{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition_test_twins.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "vVK2IxQBIK5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "192f0a87-0220-4365-b4c4-7fde3f449623"
      },
      "cell_type": "code",
      "source": [
        "!pip install CMake\n",
        "!pip install face_recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting CMake\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/ee/36a244e43fc9ea64a2aab9ec854616a1771c11e91ae97d7b34246f922668/cmake-3.12.0-cp36-cp36m-manylinux1_x86_64.whl (17.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.7MB 1.5MB/s \n",
            "\u001b[?25hInstalling collected packages: CMake\n",
            "Successfully installed CMake-3.12.0\n",
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/28/10/f153bbbc218fc169768aa1c02f2e9178e9241e4af8da56289bdca2c0c217/face_recognition-1.2.2-py2.py3-none-any.whl\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 100.2MB 352kB/s \n",
            "\u001b[?25hCollecting dlib>=19.7 (from face_recognition)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/aa/6a9bb2a763107bb2606d6ee1aa65fcd3b51375a9ef6436e9c9280b0dd63c/dlib-19.15.0.tar.gz (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (4.0.0)\n",
            "Collecting Click>=6.0 (from face_recognition)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/c1/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77/click-6.7-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 18.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.14.5)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->face_recognition) (0.45.1)\n",
            "Building wheels for collected packages: face-recognition-models, dlib\n",
            "  Running setup.py bdist_wheel for face-recognition-models ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "  Running setup.py bdist_wheel for dlib ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/8e/8d/4f/6a4ee32422131b30f5e483f821e359a32b5cd7abbb22dda22d\n",
            "Successfully built face-recognition-models dlib\n",
            "Installing collected packages: face-recognition-models, dlib, Click, face-recognition\n",
            "Successfully installed Click-6.7 dlib-19.15.0 face-recognition-1.2.2 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kbuXK4Y1LBeK",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "699acc68-135b-4a20-c838-1ba5d4a80888"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e12aabe-621f-4a3a-80e8-694db388aac9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8e12aabe-621f-4a3a-80e8-694db388aac9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Twins1.jpg to Twins1 (1).jpg\n",
            "Saving Twins2.jpg to Twins2 (1).jpg\n",
            "Saving Twins11.jpg to Twins11.jpg\n",
            "Saving Twins12.jpg to Twins12.jpg\n",
            "User uploaded file \"Twins1.jpg\" with length 13079 bytes\n",
            "User uploaded file \"Twins2.jpg\" with length 13945 bytes\n",
            "User uploaded file \"Twins11.jpg\" with length 13116 bytes\n",
            "User uploaded file \"Twins12.jpg\" with length 14533 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZiX1Wy2dLhu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "f0688d7f-d627-4336-f51f-f051bbec8cc6"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AB1.jpg   Ash2.jpg   BW1.jpg   hr1.jpg  PS1.jpg  rk2.jpg       un3.jpg  un8.jpg\r\n",
            "AB2.jpg   Ash3.jpg   BW2.jpg   HR1.jpg  PS2.jpg  Rock1.jpg     un4.jpg  un9.jpg\r\n",
            "ar1.jpg   Ash4.jpg   BW3.jpg   HR2.jpg  PS3.jpg  \u001b[0m\u001b[01;34msample_data\u001b[0m/  un5.jpg\r\n",
            "ar2.jpg   Ash5.jpg   BW4.jpg   JS1.jpg  rk1.jpg  un1.jpg       un6.jpg\r\n",
            "Ash1.jpg  biden.jpg  \u001b[01;36mdatalab\u001b[0m@  PP1.jpg  RK1.jpg  un2.jpg       un7.jpg\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BHlKqlUbLm4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cc0b05ec-d607-4586-a450-293bcd961ad3"
      },
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "Ash1_image = face_recognition.load_image_file(\"Ash1.jpg\")\n",
        "AB1_image = face_recognition.load_image_file(\"AB1.jpg\")\n",
        "Ash1_encoding = face_recognition.face_encodings(Ash1_image)[0]\n",
        "AB1_encoding = face_recognition.face_encodings(AB1_image)[0]\n",
        "\n",
        "results = face_recognition.compare_faces([Ash1_encoding], AB1_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sDEvsXXVOR3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "09ee2ff7-25eb-4b96-cb4e-5aebbadb4301"
      },
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "Ash1_image = face_recognition.load_image_file(\"Ash1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"un8.jpg\")\n",
        "Ash1_encoding = face_recognition.face_encodings(Ash1_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash1_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rMrYGGUdQ-mY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5422ffe8-e3f6-452c-ec42-717d7a4ea26b"
      },
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "Ash1_image = face_recognition.load_image_file(\"Ash1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"un6.jpg\")\n",
        "Ash1_encoding = face_recognition.face_encodings(Ash1_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash1_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nERy7MK1Szw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e20863aa-f9d7-46eb-9b8e-fd0f472a8535"
      },
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"Ash5.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"un8.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7s9pgC3qRIYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7dcea1b8-8097-4226-aaca-be7aa703036f"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images with child female\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"ar1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"un9.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "itJAKC9AXEII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4860a353-0054-44f3-e420-632e3e250234"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images with child female\n",
        "import face_recognition\n",
        "ar2_image = face_recognition.load_image_file(\"kk1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"KK1.jpg\")\n",
        "ar2_encoding = face_recognition.face_encodings(ar2_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([ar2_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OjghuGeiXECJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PVdANsAgUB1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5241b3ee-6436-44aa-d38b-4f442868e812"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images with young male\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"AB1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"AB2.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jXjgHiKMU6lV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e944a1be-84c2-4790-e185-4f5e3f257aa5"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images with child male\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"HR1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"hr1.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VwEe3x2pVPVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d0795053-8f8d-4353-d969-f6f6d186fd1f"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images with child male\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"RK1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"rk1.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gsUsMXDkbH5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b1460bdc-b1ad-4472-fd24-33de76e767b8"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images male\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"BW4.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"PS2.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DjAZ3AbkbiMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c7aad631-96f4-41a4-8927-99e7f898d54c"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images male\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"PS3.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"PS2.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8QRcAGSkeAGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3a3ab60c-1d72-43a2-a2a3-71881acd7440"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images male twins\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"Twins1.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"Twins2.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3E-IQQobftiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a8288c25-ee88-46e3-d013-7bb33369d325"
      },
      "cell_type": "code",
      "source": [
        "#Now check if model is going to detect images male twins\n",
        "import face_recognition\n",
        "Ash5_image = face_recognition.load_image_file(\"Twins11.jpg\")\n",
        "Unknown_image = face_recognition.load_image_file(\"Twins12.jpg\")\n",
        "Ash5_encoding = face_recognition.face_encodings(Ash5_image)[0]\n",
        "Unknown_encoding = face_recognition.face_encodings(Unknown_image)[0]\n",
        "results = face_recognition.compare_faces([Ash5_encoding], Unknown_encoding)\n",
        "print(\"Are these faces of same person - \", results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are these faces of same person -  [True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iwr5TRT1fte5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}